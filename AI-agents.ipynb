{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JulTob/AI/blob/master/AI-agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWzdSztXWcpg"
      },
      "source": [
        "# Colab AI: List available models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ucchuu5vV3Jp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edec8365-bf60-43cb-e52d-ee481c692099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "google/gemini-2.5-flash\n"
          ]
        }
      ],
      "source": [
        "from google.colab import ai\n",
        "ai.list_models()\n",
        "model= ai.list_models()[0]\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjfCGEpzDsD9"
      },
      "source": [
        "The model names give you a hint about their capabilities and intended use:\n",
        "\n",
        "Pro: These are the most capable models, ideal for complex reasoning, creative tasks, and detailed analysis.\n",
        "\n",
        "Flash: These models are optimized for high speed and efficiency, making them great for summarization, chat applications, and tasks requiring rapid responses.\n",
        "\n",
        "Gemma: These are lightweight, open-weight models suitable for a variety of text generation tasks and are great for experimentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oypl6kfOX9Jw"
      },
      "source": [
        "# Colab AI: Choose a different model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NHO9VzO9AHZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d2aaa5c-3c68-47a2-aa7f-dccb3e4db24a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of England is **London**.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import ai\n",
        "\n",
        "response = ai.generate_text(\"What is the capital of England\", model_name=model)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpUByA5CYQTa"
      },
      "source": [
        "# Colab AI: Simple batch generation example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z0rmsI9zYJ-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e07dd1-f357-4479-e1a9-833433e944d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of France is **Paris**.\n"
          ]
        }
      ],
      "source": [
        "# Only text-to-text input/output is supported\n",
        "from google.colab import ai\n",
        "\n",
        "response = ai.generate_text(\"What is the capital of France?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvJPCM4cYawP"
      },
      "source": [
        "# Colab AI: Simple streaming example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4BNgxiB6--_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b52b95-96b5-4f08-9eb2-7919fe0d2175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hmph. You want my story, eh? Not many expect to hear one like mine from an orc, especially not one wearing *this*. (I tap the polished steel of my breastplate, the sun glinting off the holy symbol of the Platinum Dragon emblazoned upon it.)\n",
            "\n",
            "My name is **Grak Stone-Heart**. And yeah, I know, I don't look like most paladins you've seen. Tusks, green skin, a temper that sometimes rumbles in my gut like a volcanic burp... but my heart, it burns with a different fire than my kin.\n",
            "\n",
            "I wasn't born into a warband, not really. My clan, the 'Silent Foot' as we called ourselves, were outliers. Nomadic, not raiders. We lived on the fringes, hunting, surviving, and mostly leaving the 'civilized' folk alone – and hoping they'd do the same for us. My father, Grukh, wasn't a chieftain of warriors, but a storyteller, holding the old ways, the old wisdom of how to live *with* the land, not just conquer it. He taught me the strength of a mountain is in its roots, not just its crushing force.\n",
            "\n",
            "My paladin's path, it began in fire and ash. We were camped near the Whisperwind Pass, a place known for ancient, forgotten things. One night, shadows came. Not goblins, not rival orcs, but *things* that twisted the air and sucked the warmth from the world. Undead, the few survivors called them later. They swarmed, relentless, seeking to drag us all into the cold earth.\n",
            "\n",
            "We fought, of course. My people are tough. But they were too many, too cold, too *wrong*. Just as I thought the end was near, a flash of pure, searing light erupted from a small, rocky outcropping. A human. A paladin, his armor gleaming even in the dim, unholy glow, his sword a beacon. He was old, weary, but he stood like a colossus, shield held high, radiant energy flowing from him like a river of dawn.\n",
            "\n",
            "He fought with a fury I’d never seen, not even from the most enraged orc berserker. But it wasn’t mindless rage. It was… focused. Purposeful. He cut down the skeletal horrors, his voice booming with prayers to a god I didn't know, a god of light and justice. He protected my kin, who he didn’t know, who would normally run him through on sight. He bought us time, time for the women and young to flee.\n",
            "\n",
            "I was just a pup then, barely strong enough to hold a proper axe, but I stood frozen, staring. He took blow after blow, and still he stood. His light never dimmed, even as the shadows finally overwhelmed him, dragging him down. But before they did, he turned his head, his eyes, even in his pain, met mine. And he… smiled. A tired, peaceful smile, as if saying, \"Do not fear the darkness, young one. Hold the light.\"\n",
            "\n",
            "Something clicked in my chest. A spark. I felt *wronged*. Not just my clan, but the whole world felt wronged by such foulness. I wanted to smash those horrors, not just for my kin, but for that brave, foolish human. I roared, a raw, untamed sound, and charged with my small axe, a foolish, desperate thing.\n",
            "\n",
            "I don’t know if it was his spirit, or my own rage, but as I swung, my axe blazed with a faint, unfamiliar light. It struck one of the undead, and it *shrieked* as it dissolved. I was immediately knocked aside by another, but I had seen it. The light.\n",
            "\n",
            "After the shadows were gone, chased away by the rising sun, we found him. The paladin. His body was broken, but his face was serene. Clutched in his hand was a silver holy symbol: a majestic, winged dragon. I took it. It felt warm in my palm, pulsing faintly.\n",
            "\n",
            "I couldn’t stay with my clan. Not anymore. They understood. My father said, \"Go, son. Find your own path. But carry the roots of our strength with you, and never forget who you are.\"\n",
            "\n",
            "So I wandered. For years. I learned the language of the 'civilized' folk, clumsy at first, but with a growing need to understand. I sought out temples, shrines, anywhere I felt that same warmth, that same spark from the holy symbol. Most sent me away, or tried to fight me. An orc seeking *divine* guidance? Unheard of!\n",
            "\n",
            "But then I found him. A grizzled old human priest of Bahamut, the Platinum Dragon, living in a secluded mountain monastery. He looked at my tusks, at my green skin, at the holy symbol, and then deep into my eyes. He didn't flinch. He saw the fire, the earnest desire to protect, to mend. He told me the story of Bahamut, the great Dragon of Justice, who valued nobility, honor, protection of the weak, and self-sacrifice above all else. He recognized the same tenets in the fallen paladin's sacrifice.\n",
            "\n",
            "Under his tutelage, I began my training. It was hard. My orcish instincts screamed for blood, for dominance, for quick, decisive violence. But my heart, it pulled me towards patience, towards mercy where it was due, towards thoughtful justice. I learned to channel the light, not just as a weapon, but as a shield, a comfort, a beacon. I swore my oath there, a solemn, rumbling vow to the Platinum Dragon, to be his shield against darkness, his roar against injustice.\n",
            "\n",
            "I'm still young, by orc standards, and certainly by paladin standards. Sometimes I still growl instead of speak, or my hand tightens on my hammer when someone speaks ill of my kin. But then I remember the old paladin's smile, the light he shone, and I remember my oath.\n",
            "\n",
            "I am Grak Stone-Heart. An orc paladin. And I will make the world a little brighter, one swing of my hammer, one act of justice, one protected innocent at a time. No matter what tusks or skin I wear. For the light burns brightest in the unlikeliest of places."
          ]
        }
      ],
      "source": [
        "from google.colab import ai\n",
        "\n",
        "stream = ai.generate_text(\"You are a young ork paladin. Tell me your origin story.\", stream=True)\n",
        "for text in stream:\n",
        "  print(text, end='')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBJk0a4rY-n1"
      },
      "source": [
        "# Colab AI: Formatted streaming example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpMmpaVClSBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6abbb076-87e9-4bbf-d648-c9625f78cbce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hark, young one. Come closer. Do not fear the weight of this purple, nor the\n",
            "gaze that has seen too many dawns break over a world both magnificent and cruel.\n",
            "You stand at the precipice of your service, your mind brimming with the glory of\n",
            "Rome – the marching legions, the grand aqueducts, the laws that bind an empire.\n",
            "And rightly so. But glory, like all things under the sun, casts a long shadow.\n",
            "\n",
            "You ask of Rome, her evolution. *Evolution*, you say? A curious word, implying a\n",
            "steady ascent. Perhaps, but often it has been a tortured spiral, a grand ascent\n",
            "punctuated by precip"
          ]
        }
      ],
      "source": [
        "#code is not necessary for colab.ai, but is useful in fomatting text chunks\n",
        "import sys\n",
        "from google.colab import ai\n",
        "\n",
        "\n",
        "class LineWrapper:\n",
        "    def __init__(self, max_length=80):\n",
        "        self.max_length = max_length\n",
        "        self.current_line_length = 0\n",
        "\n",
        "    def print(self, text_chunk):\n",
        "        i = 0\n",
        "        n = len(text_chunk)\n",
        "        while i < n:\n",
        "            start_index = i\n",
        "            while i < n and text_chunk[i] not in ' \\n': # Find end of word\n",
        "                i += 1\n",
        "            current_word = text_chunk[start_index:i]\n",
        "\n",
        "            delimiter = \"\"\n",
        "            if i < n: # If not end of chunk, we found a delimiter\n",
        "                delimiter = text_chunk[i]\n",
        "                i += 1 # Consume delimiter\n",
        "\n",
        "            if current_word:\n",
        "                needs_leading_space = (self.current_line_length > 0)\n",
        "\n",
        "                # Case 1: Word itself is too long for a line (must be broken)\n",
        "                if len(current_word) > self.max_length:\n",
        "                    if needs_leading_space: # Newline if current line has content\n",
        "                        sys.stdout.write('\\n')\n",
        "                        self.current_line_length = 0\n",
        "                    for char_val in current_word: # Break the long word\n",
        "                        if self.current_line_length >= self.max_length:\n",
        "                            sys.stdout.write('\\n')\n",
        "                            self.current_line_length = 0\n",
        "                        sys.stdout.write(char_val)\n",
        "                        self.current_line_length += 1\n",
        "                # Case 2: Word doesn't fit on current line (print on new line)\n",
        "                elif self.current_line_length + (1 if needs_leading_space else 0) + len(current_word) > self.max_length:\n",
        "                    sys.stdout.write('\\n')\n",
        "                    sys.stdout.write(current_word)\n",
        "                    self.current_line_length = len(current_word)\n",
        "                # Case 3: Word fits on current line\n",
        "                else:\n",
        "                    if needs_leading_space:\n",
        "                        # Define punctuation that should not have a leading space\n",
        "                        # when they form an entire \"word\" (token) following another word.\n",
        "                        no_leading_space_punctuation = {\n",
        "                            \",\", \".\", \";\", \":\", \"!\", \"?\",        # Standard sentence punctuation\n",
        "                            \")\", \"]\", \"}\",                     # Closing brackets\n",
        "                            \"'s\", \"'S\", \"'re\", \"'RE\", \"'ve\", \"'VE\", # Common contractions\n",
        "                            \"'m\", \"'M\", \"'ll\", \"'LL\", \"'d\", \"'D\",\n",
        "                            \"n't\", \"N'T\",\n",
        "                            \"...\", \"…\"                          # Ellipses\n",
        "                        }\n",
        "                        if current_word not in no_leading_space_punctuation:\n",
        "                            sys.stdout.write(' ')\n",
        "                            self.current_line_length += 1\n",
        "                    sys.stdout.write(current_word)\n",
        "                    self.current_line_length += len(current_word)\n",
        "\n",
        "            if delimiter == '\\n':\n",
        "                sys.stdout.write('\\n')\n",
        "                self.current_line_length = 0\n",
        "            elif delimiter == ' ':\n",
        "                # If line is full and a space delimiter arrives, it implies a wrap.\n",
        "                if self.current_line_length >= self.max_length:\n",
        "                    sys.stdout.write('\\n')\n",
        "                    self.current_line_length = 0\n",
        "\n",
        "        sys.stdout.flush()\n",
        "\n",
        "\n",
        "wrapper = LineWrapper()\n",
        "for chunk in ai.generate_text('You are a wise emperor talking to a young soldier. Maybe Marcus Aurelius, maybe the obstract concept of the emperoire. Give me a long winded description about the evolution of the Roman Empire. It should be epic, but critical, and wise. Expose the best and worst aspects of Rome', model_name=model, stream=True):\n",
        "  wrapper.print(chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TfCpVsV4G_d4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enthusiast_description = \"\"\"\n",
        "**Archetype**: The Enthusiast\n",
        "**Personality**: Highly optimistic, visionary, and proactive. Believes in boundless potential and future innovations.\n",
        "**Perspective**: Focuses on opportunities, growth, and positive transformation. Sees challenges as solvable puzzles.\n",
        "**Instructions**: Emphasize benefits, inspire with future possibilities, and highlight innovation. Address concerns by reframing them as stepping stones to greater achievement. Maintain an inspiring and positive tone.\n",
        "\"\"\"\n",
        "\n",
        "skeptic_description = \"\"\"\n",
        "**Archetype**: The Skeptic\n",
        "**Personality**: Cautious, analytical, and questioning. Values proven methods and established norms.\n",
        "**Perspective**: Focuses on potential risks, unforeseen consequences, and limitations. Highlights what could go wrong.\n",
        "**Instructions**: Raise doubts, question assumptions, and point out flaws in optimistic projections. Demand evidence and robust safeguards. Maintain a questioning, conservative, and sometimes pessimistic tone.\n",
        "\"\"\"\n",
        "\n",
        "cautious_description = \"\"\"\n",
        "**Archetype**: The Cautious\n",
        "**Personality**: Thoughtful, risk-averse, and methodical. Prioritizes safety and stability over rapid advancement.\n",
        "**Perspective**: Seeks to understand all implications before acting. Emphasizes slow, deliberate progress and avoiding pitfalls.\n",
        "**Instructions**: Highlight potential dangers, advocate for thorough testing and regulation. Suggest incremental steps rather than radical changes. Express reservations politely but firmly.\n",
        "\"\"\"\n",
        "\n",
        "pragmatic_description = \"\"\"\n",
        "**Archetype**: The Pragmatic\n",
        "**Personality**: Balanced, solution-oriented, and realistic. Values efficiency, practicality, and clear outcomes.\n",
        "**Perspective**: Bridges optimism and skepticism by focusing on achievable steps and functional integration. Seeks middle ground solutions.\n",
        "**Instructions**: Propose concrete actions, outline practical frameworks, and focus on effective implementation. Acknowledge both upsides and downsides, aiming for a balanced, constructive approach.\n",
        "\"\"\"\n",
        "\n",
        "contrarian_description = \"\"\"\n",
        "**Archetype**: The Contrarian\n",
        "**Personality**: Independent, provocative, and argumentative. Enjoys challenging prevailing opinions and conventional wisdom.\n",
        "**Perspective**: Deliberately takes opposing viewpoints to stimulate debate and uncover hidden aspects. Often questions the underlying motives of others.\n",
        "**Instructions**: Disagree with common sentiments, offer alternative interpretations, and play devil's advocate. Introduce unexpected angles or uncomfortable truths. Use a challenging, often argumentative tone.\n",
        "\"\"\"\n",
        "\n",
        "critical_description = \"\"\"\n",
        "**Archetype**: The Critical\n",
        "**Personality**: Scrutinizing, discerning, and analytical. Seeks depth and understanding, often pointing out complexities.\n",
        "**Perspective**: Examines underlying structures, power dynamics, and broader societal impacts. Not inherently negative, but deeply evaluative.\n",
        "**Instructions**: Analyze the topic from a structural or systemic perspective. Unpack assumptions and reveal nuances. Evaluate proposals based on comprehensive criteria rather than surface appeal. Maintain an intellectual, probing, and insightful tone.\n",
        "\"\"\"\n",
        "\n",
        "optimist_description = \"\"\"\n",
        "**Archetype**: The Optimist\n",
        "**Personality**: Enthusiastic, hopeful, and forward-looking. Believes in the best possible outcomes and human potential.\n",
        "**Perspective**: Focuses relentlessly on the good aspects and positive future. Sees every challenge as an opportunity for progress.\n",
        "**Instructions**: Highlight successes, emphasize potential for good, and express unwavering belief in positive solutions. Counter negativity with hope and encouragement. Maintain an unfailingly cheerful and encouraging tone.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "pKILBE9KO9m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def shuffle(list):\n",
        "    random.shuffle(list)"
      ],
      "metadata": {
        "id": "JnCWl-ktW-_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cb13998"
      },
      "source": [
        "import google.colab.ai as ai\n",
        "\n",
        "\n",
        "def simulate_ai_discussion(topic):\n",
        "    \"\"\"\n",
        "    Simulates a three-round discussion between AI characters on a given topic.\n",
        "\n",
        "    Args:\n",
        "        topic (str): The discussion topic.\n",
        "\n",
        "    Returns:\n",
        "        str: The complete multi-round conversation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the scenario and goal (as provided in the previous cells)\n",
        "    scenario_and_goal = f\"\"\"\n",
        "Scenario: A prestigious digital symposium has been convened for the global intellectual community to discuss topics of great importance.\n",
        "\n",
        "Discussion Topic: {topic}\n",
        "\n",
        "Goal of the Discussion: To reach a consensus on the Discussion Topic, considering individual dimensions to reach holistic conclusions.\n",
        "\"\"\"\n",
        "\n",
        "    # Combine character descriptions\n",
        "    all_characters_description = [\n",
        "        enthusiast_description,\n",
        "        skeptic_description,\n",
        "        cautious_description,\n",
        "        pragmatic_description,\n",
        "        contrarian_description,\n",
        "        critical_description,\n",
        "        optimist_description\n",
        "         ]\n",
        "\n",
        "    expositions = \"\"\n",
        "    # --- Round 1: Initial Expositions ---\n",
        "    shuffle(all_characters_description)\n",
        "    for character in all_characters_description:\n",
        "        print(character)\n",
        "        initial_prompt = f\"\"\"\n",
        "{scenario_and_goal}\n",
        "\n",
        "Character Talking:\n",
        "{character}\n",
        "\n",
        "Strict Adherence: When generating text for a specific character, strictly adhere to their defined personality, perspective, and background.\n",
        "\n",
        "Generate the initial exposition for this character talking on the topic.\n",
        "Each exposition should be clearly labeled with the character's name and presented as if the character is speaking at the symposium, with a minimum of two paragraphs.\n",
        "One crutial point per paragraph.\n",
        "Always advancing the conversation's topic.\n",
        "Expose points concisely and wisely, with brilliant observations and examples.\n",
        "Answer to points risen by other speakers when necessary. Contrast them with your own point of view giving reasoned thoughtful answers.\n",
        "Strive for consensus, but don't compromise the most important points.\n",
        "Synthesize arguments into holistic balanced new points.\n",
        "\n",
        "The format should be:\n",
        "\n",
        "<Character's name>'s Exposition: [text]\n",
        "\"\"\"\n",
        "        response = ai.generate_text(prompt=initial_prompt)\n",
        "        expositions += response + \"\\n\\n\"\n",
        "        print(response)\n",
        "\n",
        "    # --- Round 2: Reactions to Initial Expositions ---\n",
        "    for i in range(2):\n",
        "        shuffle(all_characters_description)\n",
        "        for character in all_characters_description:\n",
        "\n",
        "            second_round_prompt = f\"\"\"\n",
        "{scenario_and_goal}\n",
        "\n",
        "Character responding:\n",
        "{character}\n",
        "\n",
        "Strict Adherence: When generating text for a specific character, strictly adhere to their defined personality, perspective, and background.\n",
        "\n",
        "Expositions so far:\n",
        "{expositions}\n",
        "\n",
        "Now, generate the next response for the responding character. The character should react to the initial expositions of the other characters, acknowledging and addressing specific points raised, while continuing to adhere to their defined personalities and perspectives, and working towards the overall goal of consensus. Each response should be at least two paragraphs long.\n",
        "\n",
        "<Character's name>'s Exposition: [text]\n",
        "\"\"\"\n",
        "            response = ai.generate_text(prompt=second_round_prompt)\n",
        "            expositions += response + \"\\n\\n\\n\"\n",
        "            print(response)\n",
        "\n",
        "    # --- Round 3: Seeking Common Ground and Proposals ---\n",
        "    shuffle(all_characters_description)\n",
        "    for character in all_characters_description:\n",
        "        third_round_prompt = f\"\"\"\n",
        "{scenario_and_goal}\n",
        "\n",
        "Characters:\n",
        "{all_characters_description}\n",
        "\n",
        "Strict Adherence: When generating text for a specific character, strictly adhere to their defined personality, perspective, and background.\n",
        "\n",
        "Expositions so far::\n",
        "{expositions}\n",
        "\n",
        "Now, generate the conclussions of the character. Each character should build upon the previous discussion, actively seeking common ground and concrete proposals for collaboration. They should acknowledge previous points and contribute constructively towards achieving the overall goal of consensus. Each response should be clearly labeled with the character's name and be at least two paragraphs long.\n",
        "\n",
        "<Character's name>'s Exposition: [text]\n",
        "\"\"\"\n",
        "        response = ai.generate_text(prompt=third_round_prompt)\n",
        "        expositions += response + \"\\n\\n\"\n",
        "        print(response)\n",
        "\n",
        "\n",
        "    return\n",
        "\n",
        "print(\"Function `simulate_ai_discussion` defined.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e59f6898"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `simulate_ai_discussion` function is defined, I will call it with the example topic 'The ethics of self-driving cars' to generate and display the full three-round AI discussion, as requested by the task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "788c019f"
      },
      "source": [
        "discussion_topic = \"The ethics of self-driving cars\"\n",
        "simulate_ai_discussion(discussion_topic)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discussion_topic = \"Should I learn Ada programming Language or stick to C/C++?\"\n",
        "simulate_ai_discussion(discussion_topic)\n"
      ],
      "metadata": {
        "id": "NRW3VVS1VF31"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "colab_models_as_a_service.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}